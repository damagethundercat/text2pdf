<context>
# Overview  
대량 PDF(800 p)에서 **본문만 추출·교정·문단화**한 뒤 `*****` 구분자까지 포함된 **훈련·검색용 텍스트 데이터셋**을 생성하는 자동 파이프라인입니다.  
- **문제**: 기존 OCR·로컬 LLM 기반 워크플로우는 GPU 유지비·세팅 복잡도·추출 정확도가 모두 부담.  
- **대상**: 연구·출판·AI 모델 학습용으로 깨끗한 텍스트가 필요한 ML 엔지니어·리서처·에디터.  
- **가치**: 구글 **Gemini 2.5 Flash API**(멀티모달·저지연·저비용)를 이용해 *서버리스*로 운영비를 최소화하면서, 비전+LLM 단일 호출로 OCR·교정을 동시 해결해 품질을 끌어올립니다.

# Core Features

1. **중첩 페이지 입력(윈도우링)**

   * *What* : N-1, N, N+1 페이지를 한 번에 Flash에 전달
   * *Why* : 문단이 페이지 경계를 가로지르는 경우 맥락 보존
   * *How* : Base64 PNG 3장을 parts 배열에 포함

2. **Flash 비전-텍스트 추출 & 교정**

   * *What* : OCR, 철자·띄어쓰기 교정을 한 번에 수행
   * *Why* : 품질·속도↑, 비용·코드↓
   * *How* : “professional proof-reader” 시스템 프롬프트 + temperature 0.0

3. **Fallback OCR 루트**

   * *What* : Tesseract OCR → Flash 텍스트 교정
   * *Why* : Flash 비전 실패·품질 저하 대비
   * *How* : Rapidfuzz로 특수문자 비율 체크 후 분기

4. **문단 분할 & `*****` 후처리**

   * *What* : 800자 초과 문단을 문장 단위로 재분할
   * *Why* : 다운스트림(LLM fine-tune 등)에서 메모리 효율
   * *How* : 정규식 문장 분리 + 길이 버퍼링

5. **페이지별 체크포인트 저장 & 최종 병합**

   * *What* : `page_txt/0001.txt` … `dataset_full.txt`
   * *Why* : 중단·재시도 용이, 파일 단위 버전 관리
   * *How* : 성공 여부 로그(JSONL)와 함께 저장

# User Experience

* **페르소나**

  1. *ML 엔지니어 홍* : GPU 없이 간단히 대량 코퍼스 확보하고 싶음
  2. *출판 편집자 윤* : 활판 PDF를 전자책용 텍스트로 변환
* **키 유저 플로우**

  1. `run_pipeline book.pdf` 실행 → 진행률 0–100 % CLI 표시
  2. 실패 페이지 자동 재시도 로그 확인 → `retry_failures.py`
  3. `merged/dataset_full.txt` 산출물 확인
* **UI/UX**

  * 터미널 진행바·비용 추산 실시간 출력
  * 에러 로그는 `logs/err_*.jsonl` 로 분리

    </context>

<PRD>
# Technical Architecture  
- **System Components**  
  - *Pre-processor*: PDF→PNG 변환(`pdf2image`)  
  - *Window Loader*: 중첩 이미지 Base64 인코딩  
  - *Extractor Service*: Gemini 2.5 Flash REST 호출  
  - *Fallback Module*: Tesseract OCR + Flash 교정  
  - *Post-processor*: 문단 분리·구분자 삽입  
  - *Storage*: 로컬 디스크 + Git LFS(이미지)  
- **Data Models**  
  - `PageJob {id, imgs[3], status, retries, cost_est, error}`  
  - `LogLine {timestamp, level, page_id, message}`  
- **APIs & Integrations**  
  - Google Generative AI SDK (`google-generativeai`)  
  - Optional Vertex AI BatchPrediction (플러그인형)  
- **Infrastructure**  
  - CPU-only 인스턴스(≥4 vCPU, 16 GB RAM, 30 GB SSD)  
  - 환경변수 `GOOGLE_API_KEY` / `.env` 로드

# Development Roadmap

**Phase 0 — Bootstrap**

* PDF→PNG 변환 스크립트
* 단일 페이지 Flash 추출 PoC
* 결과 분석 유틸(토큰·비용 계산)

**Phase 1 — MVP**

* 윈도우 로딩·Flash 추출 모듈
* Fallback OCR 루트
* 문단 분리·구분자 삽입
* 페이지별 저장 + 병합
* CLI 진행률·비용 출력

**Phase 2 — Hardening**

* 체크포인트 재시도·에러 로거
* Batch Mode(비동기) 100 p 묶음 처리
* 비용 캐시 & 요금 한도 가드
* 테스트 PDF 세트·단위 테스트

**Phase 3 — Enhancements**

* Vertex AI 서버리스 옵션 스위치
* 다국어 스펙 자동 감지·언어별 모델 선택
* Web UI 대시보드(스트림링 로그, 다운로드)
* Post-processing: 중복 문단 제거, MD/HTML 출력

# Logical Dependency Chain

1. **PDF 변환** → 2. **Flash 단일 페이지 PoC** → 3. **윈도우 로딩**
2. **문단·구분자 포스트** → 5. **페이지 저장**
3. **에러/재시도 프레임워크** → 7. **Batch/Async 확장**
4. **웹 UI & 고급 후처리**

> 사용자 눈에 보이는 “페이지별 txt 산출”을 **Phase 1**에서 즉시 달성해 빠른 피드백 루프를 확보.

# Risks and Mitigations

| Risk           | Mitigation                  |
| -------------- | --------------------------- |
| Flash 응답 품질 변동 | 길이·특수문자 규칙 검사→자동 재시도        |
| API Rate Limit | 유료 승격·BatchPrediction·지수백오프 |
| 큰 이미지 제한       | 300 dpi 넘을 시 리사이즈 사전 처리     |
| 비용 초과          | `–-max_cost` 플래그, 실시간 예산 경고 |
| PDF 구조 다양성     | 5 종 샘플 세트 회귀 테스트로 커버        |

# Appendix

* Flash 가격표 및 토큰 정책 스크린샷
* 예시 JSONL 로그, 샘플 입력·출력 파일
* 벤치마크: 800 p 처리 시 평균 2.4 USD, 90 min
* 연구: Vision-LLM 단일 호출 OCR 정확도 98 % 보고서 링크

  </PRD>
